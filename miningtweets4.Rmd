---
title: "Mining Tweets 4"
author: "M. Calciu"
date: "18/02/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```
# 4 Relationships between words: n-grams and correlations

## 4.1 Tokenizing by n-gram

we are examining pairs of two consecutive words, often called "bigrams".
As unnesting uses as token either tweets or ngrams we had to recompose the previously unnested tweets in order to unnest them again as ngrams. 

```{r tweet_bigrams, dependson="covidtweetseng"}
library(dplyr)
library(tidytext)
library(stringr)

data("tidy_tweets")
tweet_bigrams <- tidy_tweets %>%
    group_by(month, linenumber) %>% 
    summarize(text = str_c(word, collapse = " ")) %>%
    ungroup() %>%
    unnest_tokens(bigram, text, token = "ngrams", n=2)

tweet_bigrams
```
### 4.1.1 Counting and filtering n-grams

Our usual tidy tools apply equally well to n-gram analysis. We can examine the most common bigrams using dplyr's `count()`:

```{r, dependson = "tweet_bigrams"}
tweet_bigrams %>%
  count(bigram, sort = TRUE)
```
As one might expect, a lot of the most common bigrams are pairs of common (uninteresting) words, such as of the and to be: what we call “stop-words” (see Chapter 1). This is a useful time to use tidyr’s separate(), which splits a column into multiple based on a delimiter. This lets us separate it into two columns, “word1” and “word2”, at which point we can remove cases where either is a stop-word.


```{r bigram_counts, dependson = "tweet_bigrams"}
library(tidyr)

bigrams_separated <- tweet_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) #%>%
  #filter(!word1 == "https") %>%
  #filter(!word2 == "https") %>%
  #filter(!word2 == "t.co")
# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_counts
```
In other analyses, we may want to work with the recombined words. tidyr's `unite()` function is the inverse of `separate()`, and lets us recombine the columns into one. Thus, "separate/filter/count/unite" let us find the most common bigrams not containing stop-words.

```{r bigrams_united, dependson = "bigram_counts"}
bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

bigrams_united
```
In other analyses you may be interested in the most common trigrams, which are consecutive sequences of 3 words. We can find this by setting `n = 3`:

```{r}
tidy_tweets %>% 
    group_by(month, linenumber) %>% 
    summarize(text = str_c(word, collapse = " ")) %>%
    ungroup() %>%
  unnest_tokens(trigram, text, token = "ngrams", n = 3) %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word,
         !word3 %in% stop_words$word) %>%
  count(word1, word2, word3, sort = TRUE)
```

### Analyzing bigrams

This one-bigram-per-row format is helpful for exploratory analyses of the urls starting with https ..


```{r bigrams_filtered_street, dependson = "bigram_counts"}
bigrams_filtered %>%
  filter(word2 == 'https') %>%
  count(month, word1, sort = TRUE)
```
A bigram can also be treated as a term in a document in the same way that we treated individual words. For example, we can look at the tf-idf

```{r bigram_tf_idf, dependson = "bigram_counts"}
bigram_tf_idf <- bigrams_united %>%
  count(month, bigram) %>%
  bind_tf_idf(bigram, month, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf
```
```{r bigramtfidf, dependson = "bigram_tf_idf", echo = FALSE, fig.width=6, fig.height=8, fig.cap = "Bigrams with the highest tf-idf from each month CovidTweeets"}
library(ggplot2)

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  group_by(month) %>%
  slice_max(tf_idf, n = 10) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(tf_idf, bigram, fill = month)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ month, ncol = 2, scales = "free") +
  labs(x = "tf-idf of bigram", y = NULL)
```
### Using bigrams to provide context in sentiment analysis
Now that we have the data organized into bigrams, it's easy to tell how often words are preceded by a word like "not":

```{r dependson = "bigrams_separated"}
bigrams_separated %>%
  filter(word1 == "no") %>%
  count(word1, word2, sort = TRUE)
```

We can then examine the most frequent words that were preceded by "not" and were associated with a sentiment.
...

### Visualizing a network of bigrams with ggraph

We may be interested in visualizing all of the relationships among words simultaneously, rather than just the top few at a time.

 As one common visualization, we can arrange the words into a network, or "graph." Here we'll be referring to a "graph" not in the sense of a visualization, but as a combination of connected nodes. A graph can be constructed from a tidy object since it has three variables:

* **from**: the node an edge is coming from
* **to**: the node an edge is going towards
* **weight**: A numeric value associated with each edge

The [igraph](http://igraph.org/) package has many powerful functions for manipulating and analyzing networks. One way to create an igraph object from tidy data is the `graph_from_data_frame()` function, which takes a data frame of edges with columns for "from", "to", and edge attributes (in this case `n`):

```{r bigram_graph, dependson = "bigram_counts"}
library(igraph)

# original counts
bigram_counts

# filter for only relatively common combinations
bigram_graph <- bigram_counts %>%
  filter(n > 20) %>%
  graph_from_data_frame()

bigram_graph
```

We can convert an igraph object into a ggraph with the `ggraph` function, after which we add layers to it, much like layers are added in ggplot2. For example, for a basic graph we need to add three layers: nodes, edges, and text.

```{r bigramgraph, dependson = "bigram_graph", fig.width = 9, fig.height = 7, fig.cap = "Common bigrams in Covid Tweets, showing those that occurred more than 20 times and where neither word was a stop word"}
library(ggraph)
set.seed(2017)

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```

We conclude with a few polishing operations to make a better looking graph (Figure \@ref(fig:bigramggraphausten2)):

* We add the `edge_alpha` aesthetic to the link layer to make links transparent based on how common or rare the bigram is
* We add directionality with an arrow, constructed using `grid::arrow()`, including an `end_cap` option that tells the arrow to end before touching the node
* We tinker with the options to the node layer to make the nodes more attractive (larger, blue points)
* We add a theme that's useful for plotting networks, `theme_void()`

```{r bigramggraphausten2, dependson = "bigram_graph", fig.width = 9, fig.height = 7, fig.cap = "Common bigrams in Covid Tweets, with some polishing"}
set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```
### 4.1.5 Visualizing bigrams in other texts 

## 4.2 Counting and correlating pairs of words with the widyr package
